{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Flatten, MaxPooling2D, Conv2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27450</th>\n",
       "      <td>13</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>52</td>\n",
       "      <td>200</td>\n",
       "      <td>234</td>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27451</th>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>154</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>160</td>\n",
       "      <td>161</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27452</th>\n",
       "      <td>18</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27453</th>\n",
       "      <td>17</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27454</th>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>132</td>\n",
       "      <td>170</td>\n",
       "      <td>194</td>\n",
       "      <td>214</td>\n",
       "      <td>203</td>\n",
       "      <td>197</td>\n",
       "      <td>205</td>\n",
       "      <td>209</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27455 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          3     107     118     127     134     139     143     146     150   \n",
       "1          6     155     157     156     156     156     157     156     158   \n",
       "2          2     187     188     188     187     187     186     187     188   \n",
       "3          2     211     211     212     212     211     210     211     210   \n",
       "4         13     164     167     170     172     176     179     180     184   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27450     13     189     189     190     190     192     193     193     193   \n",
       "27451     23     151     154     157     158     160     161     163     164   \n",
       "27452     18     174     174     174     174     174     175     175     174   \n",
       "27453     17     177     181     184     185     187     189     190     191   \n",
       "27454     23     179     180     180     180     182     181     182     183   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0         153  ...       207       207       207       207       206   \n",
       "1         158  ...        69       149       128        87        94   \n",
       "2         187  ...       202       201       200       199       198   \n",
       "3         210  ...       235       234       233       231       230   \n",
       "4         185  ...        92       105       105       108       133   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27450     193  ...       132       165        99        77        52   \n",
       "27451     166  ...       198       198       198       198       198   \n",
       "27452     173  ...       121       196       209       208       206   \n",
       "27453     191  ...       119        56        27        58       102   \n",
       "27454     182  ...       108       132       170       194       214   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           206       206       204       203       202  \n",
       "1           163       175       103       135       149  \n",
       "2           199       198       195       194       195  \n",
       "3           226       225       222       229       163  \n",
       "4           163       157       163       164       179  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27450       200       234       200       222       225  \n",
       "27451       196       195       195       195       194  \n",
       "27452       204       203       202       200       200  \n",
       "27453        79        47        64        87        93  \n",
       "27454       203       197       205       209       215  \n",
       "\n",
       "[27455 rows x 785 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sign_mnist_train.csv\")\n",
    "data_test = pd.read_csv(\"sign_mnist_test.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27445</th>\n",
       "      <th>27446</th>\n",
       "      <th>27447</th>\n",
       "      <th>27448</th>\n",
       "      <th>27449</th>\n",
       "      <th>27450</th>\n",
       "      <th>27451</th>\n",
       "      <th>27452</th>\n",
       "      <th>27453</th>\n",
       "      <th>27454</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel1</th>\n",
       "      <td>107</td>\n",
       "      <td>155</td>\n",
       "      <td>187</td>\n",
       "      <td>211</td>\n",
       "      <td>164</td>\n",
       "      <td>161</td>\n",
       "      <td>134</td>\n",
       "      <td>114</td>\n",
       "      <td>169</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>133</td>\n",
       "      <td>170</td>\n",
       "      <td>149</td>\n",
       "      <td>162</td>\n",
       "      <td>189</td>\n",
       "      <td>151</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel2</th>\n",
       "      <td>118</td>\n",
       "      <td>157</td>\n",
       "      <td>188</td>\n",
       "      <td>211</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>134</td>\n",
       "      <td>42</td>\n",
       "      <td>174</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>135</td>\n",
       "      <td>172</td>\n",
       "      <td>151</td>\n",
       "      <td>168</td>\n",
       "      <td>189</td>\n",
       "      <td>154</td>\n",
       "      <td>174</td>\n",
       "      <td>181</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel3</th>\n",
       "      <td>127</td>\n",
       "      <td>156</td>\n",
       "      <td>188</td>\n",
       "      <td>212</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>74</td>\n",
       "      <td>176</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>170</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>153</td>\n",
       "      <td>172</td>\n",
       "      <td>190</td>\n",
       "      <td>157</td>\n",
       "      <td>174</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel4</th>\n",
       "      <td>134</td>\n",
       "      <td>156</td>\n",
       "      <td>187</td>\n",
       "      <td>212</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>135</td>\n",
       "      <td>99</td>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>141</td>\n",
       "      <td>177</td>\n",
       "      <td>157</td>\n",
       "      <td>176</td>\n",
       "      <td>190</td>\n",
       "      <td>158</td>\n",
       "      <td>174</td>\n",
       "      <td>185</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel780</th>\n",
       "      <td>206</td>\n",
       "      <td>163</td>\n",
       "      <td>199</td>\n",
       "      <td>226</td>\n",
       "      <td>163</td>\n",
       "      <td>55</td>\n",
       "      <td>189</td>\n",
       "      <td>225</td>\n",
       "      <td>114</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>153</td>\n",
       "      <td>229</td>\n",
       "      <td>200</td>\n",
       "      <td>196</td>\n",
       "      <td>204</td>\n",
       "      <td>79</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel781</th>\n",
       "      <td>206</td>\n",
       "      <td>175</td>\n",
       "      <td>198</td>\n",
       "      <td>225</td>\n",
       "      <td>157</td>\n",
       "      <td>48</td>\n",
       "      <td>179</td>\n",
       "      <td>227</td>\n",
       "      <td>94</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>147</td>\n",
       "      <td>228</td>\n",
       "      <td>234</td>\n",
       "      <td>195</td>\n",
       "      <td>203</td>\n",
       "      <td>47</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel782</th>\n",
       "      <td>204</td>\n",
       "      <td>103</td>\n",
       "      <td>195</td>\n",
       "      <td>222</td>\n",
       "      <td>163</td>\n",
       "      <td>238</td>\n",
       "      <td>181</td>\n",
       "      <td>227</td>\n",
       "      <td>74</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>148</td>\n",
       "      <td>228</td>\n",
       "      <td>200</td>\n",
       "      <td>195</td>\n",
       "      <td>202</td>\n",
       "      <td>64</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel783</th>\n",
       "      <td>203</td>\n",
       "      <td>135</td>\n",
       "      <td>194</td>\n",
       "      <td>229</td>\n",
       "      <td>164</td>\n",
       "      <td>255</td>\n",
       "      <td>181</td>\n",
       "      <td>228</td>\n",
       "      <td>61</td>\n",
       "      <td>178</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>139</td>\n",
       "      <td>227</td>\n",
       "      <td>222</td>\n",
       "      <td>195</td>\n",
       "      <td>200</td>\n",
       "      <td>87</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel784</th>\n",
       "      <td>202</td>\n",
       "      <td>149</td>\n",
       "      <td>195</td>\n",
       "      <td>163</td>\n",
       "      <td>179</td>\n",
       "      <td>255</td>\n",
       "      <td>179</td>\n",
       "      <td>228</td>\n",
       "      <td>57</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>196</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>194</td>\n",
       "      <td>200</td>\n",
       "      <td>93</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows Ã— 27455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      \\\n",
       "label         3      6      2      2     13     16      8     22      3   \n",
       "pixel1      107    155    187    211    164    161    134    114    169   \n",
       "pixel2      118    157    188    211    167    168    134     42    174   \n",
       "pixel3      127    156    188    212    170    172    135     74    176   \n",
       "pixel4      134    156    187    212    172    173    135     99    180   \n",
       "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "pixel780    206    163    199    226    163     55    189    225    114   \n",
       "pixel781    206    175    198    225    157     48    179    227     94   \n",
       "pixel782    204    103    195    222    163    238    181    227     74   \n",
       "pixel783    203    135    194    229    164    255    181    228     61   \n",
       "pixel784    202    149    195    163    179    255    179    228     57   \n",
       "\n",
       "          9      ...  27445  27446  27447  27448  27449  27450  27451  27452  \\\n",
       "label         3  ...     14     19     11     12     20     13     23     18   \n",
       "pixel1      189  ...    167    133    170    149    162    189    151    174   \n",
       "pixel2      189  ...    169    135    172    151    168    189    154    174   \n",
       "pixel3      189  ...    170    138    175    153    172    190    157    174   \n",
       "pixel4      190  ...    171    141    177    157    176    190    158    174   \n",
       "...         ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "pixel780    201  ...    201      0    229    153    229    200    196    204   \n",
       "pixel781    193  ...    167      0    227    147    228    234    195    203   \n",
       "pixel782    175  ...    119      0    228    148    228    200    195    202   \n",
       "pixel783    178  ...     75      0    227    139    227    222    195    200   \n",
       "pixel784    156  ...     48      0    227    196    226    225    194    200   \n",
       "\n",
       "          27453  27454  \n",
       "label        17     23  \n",
       "pixel1      177    179  \n",
       "pixel2      181    180  \n",
       "pixel3      184    180  \n",
       "pixel4      185    180  \n",
       "...         ...    ...  \n",
       "pixel780     79    203  \n",
       "pixel781     47    197  \n",
       "pixel782     64    205  \n",
       "pixel783     87    209  \n",
       "pixel784     93    215  \n",
       "\n",
       "[785 rows x 27455 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.T\n",
    "data_test = data_test.T\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 28, 28, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[1:]\n",
    "X_test = data_test[1:]\n",
    "X_train = np.array(X_train.T)\n",
    "X_test = np.array(X_test.T)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 25\n",
    "y_train = data.T[\"label\"]\n",
    "y_test = data_test.T[\"label\"]\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(n_classes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "215/215 [==============================] - 6s 23ms/step - loss: 0.0296 - accuracy: 0.9893 - val_loss: 0.6875 - val_accuracy: 0.9189\n",
      "Epoch 2/100\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.7620 - val_accuracy: 0.9116\n",
      "Epoch 3/100\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.7131 - val_accuracy: 0.9209\n",
      "Epoch 4/100\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 0.0248 - accuracy: 0.9909 - val_loss: 0.7775 - val_accuracy: 0.9176\n",
      "Epoch 5/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.7421 - val_accuracy: 0.9141\n",
      "Epoch 6/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.7524 - val_accuracy: 0.9318\n",
      "Epoch 7/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.7642 - val_accuracy: 0.9235\n",
      "Epoch 8/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.7793 - val_accuracy: 0.9225\n",
      "Epoch 9/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.7495 - val_accuracy: 0.9191\n",
      "Epoch 10/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.8499 - val_accuracy: 0.9218\n",
      "Epoch 11/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.8078 - val_accuracy: 0.9170\n",
      "Epoch 12/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 0.8312 - val_accuracy: 0.9190\n",
      "Epoch 13/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.7815 - val_accuracy: 0.9204\n",
      "Epoch 14/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.7464 - val_accuracy: 0.9200\n",
      "Epoch 15/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.7759 - val_accuracy: 0.9260\n",
      "Epoch 16/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.7798 - val_accuracy: 0.9306\n",
      "Epoch 17/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.7955 - val_accuracy: 0.9303\n",
      "Epoch 18/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.9022 - val_accuracy: 0.9254\n",
      "Epoch 19/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.7894 - val_accuracy: 0.9253\n",
      "Epoch 20/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.8431 - val_accuracy: 0.9248\n",
      "Epoch 21/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.9227 - val_accuracy: 0.9197\n",
      "Epoch 22/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.8605 - val_accuracy: 0.9294\n",
      "Epoch 23/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.8564 - val_accuracy: 0.9274\n",
      "Epoch 24/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.8064 - val_accuracy: 0.9176\n",
      "Epoch 25/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.8965 - val_accuracy: 0.9030\n",
      "Epoch 26/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.9194 - val_accuracy: 0.9290\n",
      "Epoch 27/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.8986 - val_accuracy: 0.9240\n",
      "Epoch 28/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.8835 - val_accuracy: 0.9241\n",
      "Epoch 29/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.8585 - val_accuracy: 0.9274\n",
      "Epoch 30/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.9012 - val_accuracy: 0.9216\n",
      "Epoch 31/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0102 - accuracy: 0.9961 - val_loss: 0.8825 - val_accuracy: 0.9119\n",
      "Epoch 32/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.9736 - val_accuracy: 0.9233\n",
      "Epoch 33/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.9283 - val_accuracy: 0.9257\n",
      "Epoch 34/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.8669 - val_accuracy: 0.9294\n",
      "Epoch 35/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.8762 - val_accuracy: 0.9136\n",
      "Epoch 36/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.9508 - val_accuracy: 0.9244\n",
      "Epoch 37/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.9154 - val_accuracy: 0.9294\n",
      "Epoch 38/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.8696 - val_accuracy: 0.9202\n",
      "Epoch 39/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.8271 - val_accuracy: 0.9292\n",
      "Epoch 40/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 0.8646 - val_accuracy: 0.9193\n",
      "Epoch 41/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.0288 - val_accuracy: 0.9267\n",
      "Epoch 42/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.9049 - val_accuracy: 0.9292\n",
      "Epoch 43/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.9293 - val_accuracy: 0.9247\n",
      "Epoch 44/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.9770 - val_accuracy: 0.9244\n",
      "Epoch 45/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.9498 - val_accuracy: 0.9230\n",
      "Epoch 46/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 1.0051 - val_accuracy: 0.9240\n",
      "Epoch 47/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.0542 - val_accuracy: 0.9250\n",
      "Epoch 48/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.9177 - val_accuracy: 0.9197\n",
      "Epoch 49/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.9623 - val_accuracy: 0.9272\n",
      "Epoch 50/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.8883 - val_accuracy: 0.9274\n",
      "Epoch 51/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.9290 - val_accuracy: 0.9235\n",
      "Epoch 52/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 1.0340 - val_accuracy: 0.9239\n",
      "Epoch 53/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 1.0093 - val_accuracy: 0.9156\n",
      "Epoch 54/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.9800 - val_accuracy: 0.9123\n",
      "Epoch 55/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.9800 - val_accuracy: 0.9229\n",
      "Epoch 56/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.9025 - val_accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.9029 - val_accuracy: 0.9254\n",
      "Epoch 58/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.8530 - val_accuracy: 0.9243\n",
      "Epoch 59/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.9265 - val_accuracy: 0.9200\n",
      "Epoch 60/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.9333 - val_accuracy: 0.9290\n",
      "Epoch 61/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.9674 - val_accuracy: 0.9255\n",
      "Epoch 62/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.8730 - val_accuracy: 0.9248\n",
      "Epoch 63/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.9481 - val_accuracy: 0.9299\n",
      "Epoch 64/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.9740 - val_accuracy: 0.9261\n",
      "Epoch 65/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.9712 - val_accuracy: 0.9253\n",
      "Epoch 66/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.9464 - val_accuracy: 0.9260\n",
      "Epoch 67/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.9849 - val_accuracy: 0.9275\n",
      "Epoch 68/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.9423 - val_accuracy: 0.9286\n",
      "Epoch 69/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.9181 - val_accuracy: 0.9294\n",
      "Epoch 70/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.9051 - val_accuracy: 0.9381\n",
      "Epoch 71/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.9490 - val_accuracy: 0.9198\n",
      "Epoch 72/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.9759 - val_accuracy: 0.9325\n",
      "Epoch 73/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.9952 - val_accuracy: 0.9297\n",
      "Epoch 74/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.0124 - val_accuracy: 0.9318\n",
      "Epoch 75/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.8854 - val_accuracy: 0.9296\n",
      "Epoch 76/100\n",
      "215/215 [==============================] - 6s 26ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.9396 - val_accuracy: 0.9255\n",
      "Epoch 77/100\n",
      "215/215 [==============================] - 8s 39ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.9941 - val_accuracy: 0.9269\n",
      "Epoch 78/100\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.9858 - val_accuracy: 0.9322\n",
      "Epoch 79/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.9742 - val_accuracy: 0.9281\n",
      "Epoch 80/100\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.9549 - val_accuracy: 0.9232\n",
      "Epoch 81/100\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.0895 - val_accuracy: 0.9246\n",
      "Epoch 82/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 1.1252 - val_accuracy: 0.9223\n",
      "Epoch 83/100\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 1.0077 - val_accuracy: 0.9212\n",
      "Epoch 84/100\n",
      "215/215 [==============================] - 11s 53ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.0023 - val_accuracy: 0.9262\n",
      "Epoch 85/100\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 1.0064 - val_accuracy: 0.9307\n",
      "Epoch 86/100\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 1.0359 - val_accuracy: 0.9241\n",
      "Epoch 87/100\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.0041 - val_accuracy: 0.9283\n",
      "Epoch 88/100\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.1063 - val_accuracy: 0.9248\n",
      "Epoch 89/100\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 1.1486 - val_accuracy: 0.9240\n",
      "Epoch 90/100\n",
      "215/215 [==============================] - 10s 48ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.9932 - val_accuracy: 0.9258\n",
      "Epoch 91/100\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.9150 - val_accuracy: 0.9371\n",
      "Epoch 92/100\n",
      "215/215 [==============================] - 9s 41ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 1.0019 - val_accuracy: 0.9281\n",
      "Epoch 93/100\n",
      "215/215 [==============================] - 6s 25ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.9448 - val_accuracy: 0.9286\n",
      "Epoch 94/100\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 1.1321 - val_accuracy: 0.9222\n",
      "Epoch 95/100\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.9805 - val_accuracy: 0.9283\n",
      "Epoch 96/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 1.0221 - val_accuracy: 0.9321\n",
      "Epoch 97/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 1.1435 - val_accuracy: 0.9267\n",
      "Epoch 98/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 1.0160 - val_accuracy: 0.9255\n",
      "Epoch 99/100\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.9764 - val_accuracy: 0.9221\n",
      "Epoch 100/100\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 1.0616 - val_accuracy: 0.9248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d947b3d90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x21d813d68e0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.48466257668711\n"
     ]
    }
   ],
   "source": [
    "z_predict = model.predict(X_test)\n",
    "print(np.sum(z_predict.argmax(axis=1) == y_test.argmax(axis=1)) / len(y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(z_predict.argmax())\n",
    "print(y_test.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_sign_mnist.xml\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_sign_mnist.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x21d80d39520>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = load_model(\"model_sign_mnist.xml\")\n",
    "new_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2-GPU",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "822993cc2de8065dd07929654093e8c6598914b15835bcfeccbcac84530d789c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
